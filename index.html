<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detector V5.0 (Diagn√≥stico)</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    
    <style>
        body { font-family: sans-serif; background: #f0f2f5; text-align: center; color: #333; }
        .video-container {
            width: 100%; max-width: 400px; margin: 0 auto;
            border: 5px solid #fff; border-radius: 15px;
            background: #000; overflow: hidden;
        }
        video { width: 100%; }
        #resultado {
            margin-top: 20px; font-size: 24px; font-weight: bold;
            padding: 20px; background: white; border-radius: 10px;
            display: inline-block; border: 2px solid #ddd;
        }
        #probabilidad { font-size: 16px; color: #666; margin-top: 5px; }
    </style>
</head>
<body>

    <h1>üê∂ vs üê± (V5.0)</h1>

    <div class="video-container">
        <video id="webcam" autoplay playsinline muted></video>
    </div>

    <div id="resultado">Cargando...</div>
    <div id="probabilidad"></div>
    <br>
    <button onclick="iniciarCamara()">Iniciar C√°mara</button>

    <script>
        let modelo = null;
        const video = document.getElementById('webcam');
        const resultadoDiv = document.getElementById('resultado');
        const probDiv = document.getElementById('probabilidad');

        (async () => {
            try {
                // Cargamos el grafo
                modelo = await tf.loadGraphModel('./model.json'); 
                resultadoDiv.innerText = "Modelo listo ‚úÖ";
            } catch (error) {
                resultadoDiv.innerText = "Error: " + error.message;
            }
        })();

        async function iniciarCamara() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
            video.srcObject = stream;
            video.onloadedmetadata = () => predecir();
        }

        function predecir() {
            if (modelo) {
                tf.tidy(() => {
                    // 1. Tomar imagen
                    let img = tf.browser.fromPixels(video);
                    
                    // 2. Redimensionar a 100x100
                    img = tf.image.resizeNearestNeighbor(img, [100, 100]);

                    // 3. Convertir a Blanco y Negro (Mejor m√©todo)
                    // Usamos rgbToGrayscale en lugar de mean, es m√°s preciso
                    img = tf.image.rgbToGrayscale(img); 

                    // 4. Expandir dimensi√≥n del lote (Batch) -> (1, 100, 100, 1)
                    img = img.expandDims();

                    // 5. Convertir a flotante
                    img = img.toFloat();

                    // --- PRUEBA CR√çTICA ---
                    // He eliminado el .div(255.0).
                    // Si tu modelo fue entrenado con valores 0-255, esto arreglar√° el problema.
                    // Si ves que todo sale mal, descomenta la l√≠nea de abajo:
                    // img = img.div(255.0); 

                    const prediccion = modelo.predict(img).dataSync();
                    const valor = prediccion[0]; // Valor entre 0 y 1

                    // Mostrar el n√∫mero crudo para entender qu√© pasa
                    probDiv.innerText = "Nivel de confianza: " + valor.toFixed(4);

                    // Decidir
                    if (valor >= 0.5) {
                        resultadoDiv.innerText = "üê∂ PERRO";
                        resultadoDiv.style.color = "blue";
                    } else {
                        resultadoDiv.innerText = "üê± GATO";
                        resultadoDiv.style.color = "green";
                    }
                });
            }
            requestAnimationFrame(predecir);
        }
    </script>
</body>
</html>